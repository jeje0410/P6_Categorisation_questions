{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55b3de2e-e1ec-4606-883d-e8b9dc81a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "123cbf14-4c42-479d-8bcc-5967141f67f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lecture du Fichier\n",
    "df = pd.read_csv('QueryResults.csv', sep = ',', encoding='UTF-8')\n",
    "\n",
    "#Lecture du Fichier de tags\n",
    "df_tags1 = pd.read_csv('Tags1.csv', sep = ',', encoding='UTF-8')\n",
    "df_tags2 = pd.read_csv('Tags2.csv', sep = ',', encoding='UTF-8')\n",
    "\n",
    "df_tags_full = pd.concat([df_tags1, df_tags2], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "763e3a5c-8053-497c-bfe1-b7cfb6b0d151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62193, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c08fa0f-d112-4aa4-8f4f-c72c51ff425d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16413 entries, 0 to 16412\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Id            16413 non-null  int64 \n",
      " 1   BODY          16413 non-null  object\n",
      " 2   Title         16413 non-null  object\n",
      " 3   Tags          16413 non-null  object\n",
      " 4   CreationDate  16413 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 641.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "436b8d6f-5ed7-43a7-8466-49d71c14f3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id              0.0\n",
       "BODY            0.0\n",
       "Title           0.0\n",
       "Tags            0.0\n",
       "CreationDate    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "067945a1-2c3c-40d7-b2b8-f508f3d6648f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Téléchargement des packages nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a229a9-5b96-4763-803a-852607ee9866",
   "metadata": {},
   "source": [
    "# Traitement du champs Tags\n",
    "* On détermine les 100 Tags les plus utlisés\n",
    "* On supprime tous les Tags qui ne font pas partis de ce TOP 100\n",
    "* Supression des lignes Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "35018f85-3974-456e-979a-0c6bb61419bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expression régulière pour prendre uniquement les valeurs entre <>\n",
    "tokenizer = RegexpTokenizer('(?<=\\<).*?(?=\\>)')\n",
    "\n",
    "#Création de la colonne avec ces valeurs\n",
    "df['tags_words'] = df.apply(lambda row: tokenizer.tokenize(row['Tags']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ff6c4cc4-f380-4659-8432-d016bfc9e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comptage de l'utlisation des mots\n",
    "Top_Word = nltk.FreqDist()\n",
    "Top100 = []\n",
    "for x in df['tags_words']:\n",
    "    Top_Word += nltk.FreqDist(x)\n",
    "\n",
    "for i in Top_Word.most_common()[0:100]:\n",
    "    Top100.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "d1ec870a-94e9-4f3e-b393-6d65b6ad5b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui supprime le tag si celui ci n'appartient au TOP        \n",
    "def removeNotTop100(Word_list):\n",
    "    filtered_Word_list = Word_list[:] #make a copy of the Word_list\n",
    "    for Word in Word_list: # iterate over Word_list\n",
    "        if Word not in Top100: \n",
    "            filtered_Word_list.remove(Word) # remove Word from filtered_Word_list if it is a stopword\n",
    "    if len(filtered_Word_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return filtered_Word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "1e8d1d9b-b0f7-4dde-8f20-3ebcf1b8f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppression des Tags qui ne sont pas dans le TOP\n",
    "df['processed_tags_final'] = df.apply(lambda row:removeNotTop100(row['tags_words']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "9ba129dd-b087-44f7-8058-299e6c9a88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppression des lignes sans Tags\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064223f7-88e1-4b94-ba61-0689233f354b",
   "metadata": {},
   "source": [
    "# Préprocesing du champs BODY\n",
    "* Utilisation de BEAUTIFULSOUP pour le traitement HTML\n",
    "* Puis remplacement des retours chariots et des :\n",
    "* Création du nuage de mots\n",
    "* Supression des StopWord Anglais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8460f6fc-9576-476c-a334-000aa441d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Préprocessing du champ BODY\n",
    "df['processed_body'] = df['BODY'].map(lambda x: BeautifulSoup(x, \"html.parser\").get_text())\n",
    "df['processed_body'] = df['processed_body'].map(lambda x: x.replace('\\n', ' '))\n",
    "df['processed_body'] = df['processed_body'].map(lambda x: x.replace(':', ''))\n",
    "\n",
    "#Création des nuages de mots avec NLTK\n",
    "df['processed_body2'] = df.apply(lambda row: nltk.word_tokenize(row['processed_body'],language='english'), axis=1)\n",
    "\n",
    "#Supression des StopWord\n",
    "df['processed_body_final'] = df.apply(lambda row:removeStopWord(row['processed_body2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8a457be-a700-4963-a038-0c3b7301ee14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>BODY</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>processed_body</th>\n",
       "      <th>processed_body2</th>\n",
       "      <th>processed_body_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12051</td>\n",
       "      <td>&lt;p&gt;If I inherit from a base class and want to ...</td>\n",
       "      <td>Calling the base constructor in C#</td>\n",
       "      <td>&lt;c#&gt;&lt;.net&gt;&lt;inheritance&gt;&lt;constructor&gt;</td>\n",
       "      <td>2008-08-15 07:39:23</td>\n",
       "      <td>If I inherit from a base class and want to pas...</td>\n",
       "      <td>[If, I, inherit, from, a, base, class, and, wa...</td>\n",
       "      <td>[inherit, base, class, want, pass, something, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17319422</td>\n",
       "      <td>&lt;p&gt;I am using PyCharm on Windows and want to c...</td>\n",
       "      <td>How do I set the maximum line length in PyCharm?</td>\n",
       "      <td>&lt;python&gt;&lt;pycharm&gt;&lt;pep8&gt;</td>\n",
       "      <td>2013-06-26 12:00:31</td>\n",
       "      <td>I am using PyCharm on Windows and want to chan...</td>\n",
       "      <td>[I, am, using, PyCharm, on, Windows, and, want...</td>\n",
       "      <td>[using, PyCharm, Windows, want, change, settin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                               BODY  \\\n",
       "0     12051  <p>If I inherit from a base class and want to ...   \n",
       "1  17319422  <p>I am using PyCharm on Windows and want to c...   \n",
       "\n",
       "                                              Title  \\\n",
       "0                Calling the base constructor in C#   \n",
       "1  How do I set the maximum line length in PyCharm?   \n",
       "\n",
       "                                   Tags         CreationDate  \\\n",
       "0  <c#><.net><inheritance><constructor>  2008-08-15 07:39:23   \n",
       "1               <python><pycharm><pep8>  2013-06-26 12:00:31   \n",
       "\n",
       "                                      processed_body  \\\n",
       "0  If I inherit from a base class and want to pas...   \n",
       "1  I am using PyCharm on Windows and want to chan...   \n",
       "\n",
       "                                     processed_body2  \\\n",
       "0  [If, I, inherit, from, a, base, class, and, wa...   \n",
       "1  [I, am, using, PyCharm, on, Windows, and, want...   \n",
       "\n",
       "                                processed_body_final  \n",
       "0  [inherit, base, class, want, pass, something, ...  \n",
       "1  [using, PyCharm, Windows, want, change, settin...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215e83ec-f5cb-4d47-b639-aa0d14c7fa85",
   "metadata": {},
   "source": [
    "# Fonction de suppression des StopWords Anglais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a6d96b0-7bf3-42e2-994d-42d9656d8372",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('English'))\n",
    "def removeStopWord(Word_list):\n",
    "    filtered_Word_list = Word_list[:] #make a copy of the Word_list\n",
    "    for Word in Word_list: # iterate over Word_list\n",
    "        if Word.lower() in stop_words: \n",
    "            filtered_Word_list.remove(Word) # remove Word from filtered_Word_list if it is a stopword\n",
    "    return filtered_Word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae43d2e-fa4c-466b-b618-353dbcd6dde3",
   "metadata": {},
   "source": [
    "# Préprocesing du champs Titre\n",
    "\n",
    "* Remplacement des retours chariots et des :\n",
    "* Création du nuage de mots\n",
    "* Supression des StopWord Anglais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f3521206-c260-49d4-9c89-8d36515f28a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Préprocessing du champ Title\n",
    "df['processed_title'] = df['Title'].map(lambda x: x.replace('\\n', ' '))\n",
    "df['processed_title'] = df['processed_title'].map(lambda x: x.replace(':', ''))\n",
    "\n",
    "#Création des nuages de mots avec NLTK\n",
    "df['processed_title2'] = df.apply(lambda row: nltk.word_tokenize(row['processed_title'],language='english'), axis=1)\n",
    "\n",
    "#Supression des StopWord\n",
    "df['processed_title_final'] = df.apply(lambda row:removeStopWord(row['processed_title2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "7000e833-e5f9-4608-aa35-d5c6586efa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppression des colonnes inutiles\n",
    "df.drop({'processed_body','processed_body2','tags_words','processed_title','processed_title2'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "f82ae865-702f-4687-a8ba-1870d5cf79ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "9af3cbbe-9cad-4ab1-a7fd-aef0f5ed5452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "#lemmatisation\n",
    "df['processed_title_final2'] = df.apply(lambda row:lemmatize_text(row['processed_title_final']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "81510d15-e57b-4dc9-896e-0dd5d0004186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>BODY</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>processed_body_final</th>\n",
       "      <th>processed_tags_final</th>\n",
       "      <th>processed_title_final</th>\n",
       "      <th>processed_title_final2</th>\n",
       "      <th>processed_body_final2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12051</td>\n",
       "      <td>&lt;p&gt;If I inherit from a base class and want to ...</td>\n",
       "      <td>Calling the base constructor in C#</td>\n",
       "      <td>&lt;c#&gt;&lt;.net&gt;&lt;inheritance&gt;&lt;constructor&gt;</td>\n",
       "      <td>2008-08-15 07:39:23</td>\n",
       "      <td>[inherit, base, class, want, pass, something, ...</td>\n",
       "      <td>[c#, .net]</td>\n",
       "      <td>[Calling, base, constructor, C, #]</td>\n",
       "      <td>[Calling, base, constructor, C, #]</td>\n",
       "      <td>&lt;WordNetLemmatizer&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17319422</td>\n",
       "      <td>&lt;p&gt;I am using PyCharm on Windows and want to c...</td>\n",
       "      <td>How do I set the maximum line length in PyCharm?</td>\n",
       "      <td>&lt;python&gt;&lt;pycharm&gt;&lt;pep8&gt;</td>\n",
       "      <td>2013-06-26 12:00:31</td>\n",
       "      <td>[using, PyCharm, Windows, want, change, settin...</td>\n",
       "      <td>[python]</td>\n",
       "      <td>[set, maximum, line, length, PyCharm, ?]</td>\n",
       "      <td>[set, maximum, line, length, PyCharm, ?]</td>\n",
       "      <td>&lt;WordNetLemmatizer&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32664</td>\n",
       "      <td>&lt;p&gt;Can anyone tell me if there is a way with g...</td>\n",
       "      <td>Is there a constraint that restricts my generi...</td>\n",
       "      <td>&lt;c#&gt;&lt;generics&gt;&lt;constraints&gt;</td>\n",
       "      <td>2008-08-28 16:04:49</td>\n",
       "      <td>[anyone, tell, way, generics, limit, generic, ...</td>\n",
       "      <td>[c#, generics]</td>\n",
       "      <td>[constraint, restricts, generic, method, numer...</td>\n",
       "      <td>[constraint, restricts, generic, method, numer...</td>\n",
       "      <td>&lt;WordNetLemmatizer&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8763125</td>\n",
       "      <td>&lt;p&gt;I would like to get the keys of a JavaScrip...</td>\n",
       "      <td>Get array of object's keys</td>\n",
       "      <td>&lt;javascript&gt;&lt;ecmascript-5&gt;</td>\n",
       "      <td>2012-01-06 19:12:38</td>\n",
       "      <td>[would, like, get, keys, JavaScript, object, a...</td>\n",
       "      <td>[javascript]</td>\n",
       "      <td>[Get, array, object, 's, keys]</td>\n",
       "      <td>[Get, array, object, 's, key]</td>\n",
       "      <td>&lt;WordNetLemmatizer&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33923</td>\n",
       "      <td>&lt;p&gt;Whilst starting to learn lisp, I've come ac...</td>\n",
       "      <td>What is tail recursion?</td>\n",
       "      <td>&lt;algorithm&gt;&lt;language-agnostic&gt;&lt;functional-prog...</td>\n",
       "      <td>2008-08-29 03:48:03</td>\n",
       "      <td>[Whilst, starting, learn, lisp, ,, 've, come, ...</td>\n",
       "      <td>[algorithm, language-agnostic]</td>\n",
       "      <td>[tail, recursion, ?]</td>\n",
       "      <td>[tail, recursion, ?]</td>\n",
       "      <td>&lt;WordNetLemmatizer&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33969</td>\n",
       "      <td>&lt;p&gt;We're experimenting with various ways to th...</td>\n",
       "      <td>Best way to implement request throttling in AS...</td>\n",
       "      <td>&lt;asp.net-mvc&gt;&lt;throttling&gt;</td>\n",
       "      <td>2008-08-29 04:50:50</td>\n",
       "      <td>['re, experimenting, various, ways, throttle, ...</td>\n",
       "      <td>[asp.net-mvc]</td>\n",
       "      <td>[Best, way, implement, request, throttling, AS...</td>\n",
       "      <td>[Best, way, implement, request, throttling, AS...</td>\n",
       "      <td>&lt;WordNetLemmatizer&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33978</td>\n",
       "      <td>&lt;p&gt;How would you go about finding out how much...</td>\n",
       "      <td>Find out how much memory is being used by an o...</td>\n",
       "      <td>&lt;python&gt;&lt;performance&gt;&lt;memory-profiling&gt;</td>\n",
       "      <td>2008-08-29 04:59:31</td>\n",
       "      <td>[would, go, finding, much, memory, used, objec...</td>\n",
       "      <td>[python, performance]</td>\n",
       "      <td>[Find, much, memory, used, object, Python]</td>\n",
       "      <td>[Find, much, memory, used, object, Python]</td>\n",
       "      <td>&lt;WordNetLemmatizer&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33207</td>\n",
       "      <td>&lt;p&gt;What frameworks exist to unit test Objectiv...</td>\n",
       "      <td>What is the best way to unit test Objective-C ...</td>\n",
       "      <td>&lt;objective-c&gt;&lt;cocoa&gt;&lt;unit-testing&gt;&lt;xcode&gt;</td>\n",
       "      <td>2008-08-28 19:41:30</td>\n",
       "      <td>[frameworks, exist, unit, test, Objective-C, c...</td>\n",
       "      <td>[objective-c, unit-testing, xcode]</td>\n",
       "      <td>[best, way, unit, test, Objective-C, code, ?]</td>\n",
       "      <td>[best, way, unit, test, Objective-C, code, ?]</td>\n",
       "      <td>&lt;WordNetLemmatizer&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32899</td>\n",
       "      <td>&lt;p&gt;I have some kind of test data and want to c...</td>\n",
       "      <td>How do you generate dynamic (parameterized) un...</td>\n",
       "      <td>&lt;python&gt;&lt;unit-testing&gt;&lt;parameterized-unit-test&gt;</td>\n",
       "      <td>2008-08-28 17:49:02</td>\n",
       "      <td>[kind, test, data, want, create, unit, test, i...</td>\n",
       "      <td>[python, unit-testing]</td>\n",
       "      <td>[generate, dynamic, (, parameterized, ), unit,...</td>\n",
       "      <td>[generate, dynamic, (, parameterized, ), unit,...</td>\n",
       "      <td>&lt;WordNetLemmatizer&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>33746</td>\n",
       "      <td>&lt;p&gt;At work we are being asked to create XML fi...</td>\n",
       "      <td>XML attribute vs XML element</td>\n",
       "      <td>&lt;xml&gt;&lt;xsd&gt;</td>\n",
       "      <td>2008-08-29 01:15:52</td>\n",
       "      <td>[work, asked, create, XML, files, pass, data, ...</td>\n",
       "      <td>[xml]</td>\n",
       "      <td>[XML, attribute, vs, XML, element]</td>\n",
       "      <td>[XML, attribute, v, XML, element]</td>\n",
       "      <td>&lt;WordNetLemmatizer&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id                                               BODY  \\\n",
       "0      12051  <p>If I inherit from a base class and want to ...   \n",
       "1   17319422  <p>I am using PyCharm on Windows and want to c...   \n",
       "2      32664  <p>Can anyone tell me if there is a way with g...   \n",
       "3    8763125  <p>I would like to get the keys of a JavaScrip...   \n",
       "5      33923  <p>Whilst starting to learn lisp, I've come ac...   \n",
       "6      33969  <p>We're experimenting with various ways to th...   \n",
       "7      33978  <p>How would you go about finding out how much...   \n",
       "8      33207  <p>What frameworks exist to unit test Objectiv...   \n",
       "9      32899  <p>I have some kind of test data and want to c...   \n",
       "10     33746  <p>At work we are being asked to create XML fi...   \n",
       "\n",
       "                                                Title  \\\n",
       "0                  Calling the base constructor in C#   \n",
       "1    How do I set the maximum line length in PyCharm?   \n",
       "2   Is there a constraint that restricts my generi...   \n",
       "3                          Get array of object's keys   \n",
       "5                             What is tail recursion?   \n",
       "6   Best way to implement request throttling in AS...   \n",
       "7   Find out how much memory is being used by an o...   \n",
       "8   What is the best way to unit test Objective-C ...   \n",
       "9   How do you generate dynamic (parameterized) un...   \n",
       "10                       XML attribute vs XML element   \n",
       "\n",
       "                                                 Tags         CreationDate  \\\n",
       "0                <c#><.net><inheritance><constructor>  2008-08-15 07:39:23   \n",
       "1                             <python><pycharm><pep8>  2013-06-26 12:00:31   \n",
       "2                         <c#><generics><constraints>  2008-08-28 16:04:49   \n",
       "3                          <javascript><ecmascript-5>  2012-01-06 19:12:38   \n",
       "5   <algorithm><language-agnostic><functional-prog...  2008-08-29 03:48:03   \n",
       "6                           <asp.net-mvc><throttling>  2008-08-29 04:50:50   \n",
       "7             <python><performance><memory-profiling>  2008-08-29 04:59:31   \n",
       "8           <objective-c><cocoa><unit-testing><xcode>  2008-08-28 19:41:30   \n",
       "9     <python><unit-testing><parameterized-unit-test>  2008-08-28 17:49:02   \n",
       "10                                         <xml><xsd>  2008-08-29 01:15:52   \n",
       "\n",
       "                                 processed_body_final  \\\n",
       "0   [inherit, base, class, want, pass, something, ...   \n",
       "1   [using, PyCharm, Windows, want, change, settin...   \n",
       "2   [anyone, tell, way, generics, limit, generic, ...   \n",
       "3   [would, like, get, keys, JavaScript, object, a...   \n",
       "5   [Whilst, starting, learn, lisp, ,, 've, come, ...   \n",
       "6   ['re, experimenting, various, ways, throttle, ...   \n",
       "7   [would, go, finding, much, memory, used, objec...   \n",
       "8   [frameworks, exist, unit, test, Objective-C, c...   \n",
       "9   [kind, test, data, want, create, unit, test, i...   \n",
       "10  [work, asked, create, XML, files, pass, data, ...   \n",
       "\n",
       "                  processed_tags_final  \\\n",
       "0                           [c#, .net]   \n",
       "1                             [python]   \n",
       "2                       [c#, generics]   \n",
       "3                         [javascript]   \n",
       "5       [algorithm, language-agnostic]   \n",
       "6                        [asp.net-mvc]   \n",
       "7                [python, performance]   \n",
       "8   [objective-c, unit-testing, xcode]   \n",
       "9               [python, unit-testing]   \n",
       "10                               [xml]   \n",
       "\n",
       "                                processed_title_final  \\\n",
       "0                  [Calling, base, constructor, C, #]   \n",
       "1            [set, maximum, line, length, PyCharm, ?]   \n",
       "2   [constraint, restricts, generic, method, numer...   \n",
       "3                      [Get, array, object, 's, keys]   \n",
       "5                                [tail, recursion, ?]   \n",
       "6   [Best, way, implement, request, throttling, AS...   \n",
       "7          [Find, much, memory, used, object, Python]   \n",
       "8       [best, way, unit, test, Objective-C, code, ?]   \n",
       "9   [generate, dynamic, (, parameterized, ), unit,...   \n",
       "10                 [XML, attribute, vs, XML, element]   \n",
       "\n",
       "                               processed_title_final2 processed_body_final2  \n",
       "0                  [Calling, base, constructor, C, #]   <WordNetLemmatizer>  \n",
       "1            [set, maximum, line, length, PyCharm, ?]   <WordNetLemmatizer>  \n",
       "2   [constraint, restricts, generic, method, numer...   <WordNetLemmatizer>  \n",
       "3                       [Get, array, object, 's, key]   <WordNetLemmatizer>  \n",
       "5                                [tail, recursion, ?]   <WordNetLemmatizer>  \n",
       "6   [Best, way, implement, request, throttling, AS...   <WordNetLemmatizer>  \n",
       "7          [Find, much, memory, used, object, Python]   <WordNetLemmatizer>  \n",
       "8       [best, way, unit, test, Objective-C, code, ?]   <WordNetLemmatizer>  \n",
       "9   [generate, dynamic, (, parameterized, ), unit,...   <WordNetLemmatizer>  \n",
       "10                  [XML, attribute, v, XML, element]   <WordNetLemmatizer>  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21472dba-2e44-4e01-99d3-b1dfe08d13d4",
   "metadata": {},
   "source": [
    "# Création du jeu de test et d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "480c22bc-e0c0-4ae7-8942-0288676f9a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e0a55ab4-a678-46ae-aaae-f48851ee33a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8732/3913438485.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmlp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmlp1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'processed_title_final'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'processed_body_final'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'processed_tags_final'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0my_pred1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlp1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'processed_title_final'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'processed_body_final'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PROJET5\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m         \"\"\"\n\u001b[1;32m--> 752\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    753\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PROJET5\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    391\u001b[0m         )\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfirst_pass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PROJET5\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_validate_input\u001b[1;34m(self, X, y, incremental, reset)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m   1101\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PROJET5\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    570\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PROJET5\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    957\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PROJET5\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    736\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PROJET5\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mlp1 = MLPClassifier(hidden_layer_sizes=(200, ), max_iter=200, random_state=1)\n",
    "mlp1.fit(df_train.loc[:,{'processed_title_final','processed_body_final'}].to_numpy(), df_train.loc[:,'processed_tags_final'].to_numpy())\n",
    "y_pred1 = mlp1.predict(df_test.loc['processed_title_final','processed_body_final'].to_numpy())\n",
    "\n",
    "#mlp2 = MLPClassifier(hidden_layer_sizes=(200, ), max_iter=200, random_state=1)\n",
    "#mlp2.partial_fit(df_train.loc[:,{'processed_title_final','processed_body_final'}],df_train.loc[:,'processed_tags_final'], classes=list(range(df_train.loc[:,'processed_tags_final'].shape[1])))\n",
    "#y_pred2 = mlp2.predict(x_test)\n",
    "\n",
    "print('Using `fit`:')\n",
    "print(accuracy_score(y_test, y_pred1))\n",
    "\n",
    "#print('Using `partial_fit`:')\n",
    "#print(accuracy_score(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "f6a037f6-91ac-4e7c-a410-c4c495b29303",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8732/200072061.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'processed_tags_final'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "df_train.loc[:,'processed_tags_final'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "4b41f5af-c088-4ba4-b919-d824deebcb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_multilabel_classification(n_samples=1000, n_features=10,\n",
    "                                      n_classes=5, n_labels=2,\n",
    "                                      allow_unlabeled=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "d7a803f9-f665-40a9-9f57-e176ecc7eb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  6.,  2., ...,  9.,  4., 13.],\n",
       "       [ 4.,  8.,  6., ...,  8.,  2.,  3.],\n",
       "       [ 4.,  3.,  2., ...,  2.,  5., 11.],\n",
       "       ...,\n",
       "       [ 1.,  6.,  5., ..., 10.,  8., 10.],\n",
       "       [ 3.,  5.,  3., ...,  3.,  3.,  5.],\n",
       "       [ 7.,  6.,  1., ...,  8.,  5.,  3.]])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb23c8d5-7afd-4f51-aa40-be024c00aaab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
